{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWWxEeg0clW86mMrcuG8ND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harika373/cleaning-data-data-Analysis-/blob/main/YouTube%20Trending%20Dataset%20Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNhjxhONzt7L",
        "outputId": "b86dde9d-de20-440d-b783-b7d7e1b34bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ US YouTube dataset cleaned and saved as cleaned_US_youtube.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from scipy import stats\n",
        "import csv\n",
        "\n",
        "# 1. Load CSV and JSON\n",
        "# Try reading the CSV line by line using the csv module\n",
        "data = []\n",
        "try:\n",
        "    with open(\"/content/USvideos.csv\", \"r\", encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, escapechar='\\\\', quotechar='\"')\n",
        "        header = next(reader) # Read header\n",
        "        data.append(header)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    df_yt = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error reading CSV with csv module: {e}\")\n",
        "    # Fallback to pandas read_csv with relaxed parameters if csv module fails\n",
        "    try:\n",
        "        df_yt = pd.read_csv(\"/content/USvideos.csv\", engine='python', quotechar='\"', escapechar='\\\\', on_bad_lines='skip')\n",
        "    except Exception as e_fallback:\n",
        "        print(f\"Fallback read_csv also failed: {e_fallback}\")\n",
        "        df_yt = pd.DataFrame() # Create empty dataframe if both fail\n",
        "\n",
        "\n",
        "with open(\"/content/US_category_id.json\", \"r\") as f:\n",
        "    categories = json.load(f)\n",
        "\n",
        "# Extract category mapping\n",
        "cat_mapping = {}\n",
        "for item in categories['items']:\n",
        "    cat_mapping[int(item['id'])] = item['snippet']['title']\n",
        "\n",
        "# 2. Data Integrity\n",
        "numeric_cols = ['views', 'likes', 'dislikes', 'comment_count']\n",
        "for col in numeric_cols:\n",
        "    df_yt[col] = pd.to_numeric(df_yt[col], errors='coerce').fillna(0)\n",
        "    df_yt = df_yt[df_yt[col] >= 0]  # no negatives allowed\n",
        "\n",
        "df_yt['publish_time'] = pd.to_datetime(df_yt['publish_time'], errors='coerce')\n",
        "\n",
        "# 3. Missing Data Handling\n",
        "df_yt.dropna(subset=['title', 'publish_time'], inplace=True)\n",
        "df_yt['tags'] = df_yt['tags'].fillna(\"No Tags\")\n",
        "\n",
        "# 4. Duplicate Removal\n",
        "df_yt.drop_duplicates(subset=['video_id', 'trending_date'], inplace=True)\n",
        "\n",
        "# 5. Standardization\n",
        "df_yt['title'] = df_yt['title'].str.strip()\n",
        "df_yt['category_id'] = df_yt['category_id'].map(cat_mapping)  # Replace ID with category name\n",
        "\n",
        "# 6. Outlier Detection (Z-score method)\n",
        "# Ensure numeric columns are actually numeric before calculating z-scores\n",
        "for col in numeric_cols:\n",
        "    df_yt[col] = pd.to_numeric(df_yt[col], errors='coerce')\n",
        "\n",
        "# Drop rows where numeric columns became NaN after coercion for Z-score calculation\n",
        "df_yt.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "z_scores = np.abs(stats.zscore(df_yt[numeric_cols]))\n",
        "df_yt = df_yt[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "# Save cleaned dataset\n",
        "df_yt.to_csv(\"cleaned_US_youtube.csv\", index=False)\n",
        "\n",
        "print(\"✅ US YouTube dataset cleaned and saved as cleaned_US_youtube.csv\")"
      ]
    }
  ]
}